{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Word Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1 Implement the Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculates the precision of the predicted labels\n",
    "def get_precision(y_pred, y_true):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i]:\n",
    "            if y_true[i]:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    precision = float(TP/(TP + FP))\n",
    "    return precision\n",
    "\n",
    "\n",
    "## Calculates the recall of the predicted labels\n",
    "def get_recall(y_pred, y_true):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_true[i]:\n",
    "            if y_pred[i]:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    recall = float(TP/(TP + FN))\n",
    "    return recall\n",
    "\n",
    "\n",
    "## Calculates the f-score of the predicted labels\n",
    "def get_fscore(y_pred, y_true):\n",
    "    precision = get_precision(y_pred, y_true)\n",
    "    recall = get_recall(y_pred, y_true)\n",
    "    fscore = 2 * precision * recall / (precision + recall)\n",
    "    return fscore\n",
    "\n",
    "## Print the precision, recall and f-score of the predicted labels\n",
    "def test_predictions(y_pred, y_true):\n",
    "    print('precision: ' + str(get_precision(y_pred, y_true)))\n",
    "    print('recall: ' + str(get_recall(y_pred, y_true)))\n",
    "    print('f-score: ' + str(get_fscore(y_pred, y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above functions recive a vector of predictions and a vector of true labels, and compute a score that implies the quality of the predictions. The computed score are: precision, recall, and f-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2 Baselines\n",
    "### 1.2.1 Majority Class Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training precision: 0.43275\n",
      "Training recall: 1.0\n",
      "Training f-score: 0.604083057058105\n",
      "Development precision: 0.418\n",
      "Development recall: 1.0\n",
      "Development f-score: 0.5895627644569816\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "## Loads in the words and labels of one of the datasets\n",
    "def load_file(data_file):\n",
    "    words = []\n",
    "    labels = []\n",
    "    with open(data_file, 'rt', encoding=\"utf8\") as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            if i > 0:\n",
    "                line_split = line[:-1].split(\"\\t\")\n",
    "                words.append(line_split[0].lower())\n",
    "                labels.append(int(line_split[1]))\n",
    "            i += 1\n",
    "    return words, labels\n",
    "\n",
    "\n",
    "### 1.2.1: A very simple baseline\n",
    "\n",
    "## Labels every word complex\n",
    "def all_complex(data_file):\n",
    "    _, y_true = load_file(data_file)\n",
    "    y_pred = list(itertools.repeat(1, len(y_true)))  # create list of complex labels\n",
    "    precision = get_precision(y_pred, y_true)\n",
    "    recall = get_recall(y_pred, y_true)\n",
    "    fscore = get_fscore(y_pred, y_true)\n",
    "    performance = [precision, recall, fscore]\n",
    "    return performance\n",
    "\n",
    "data_file = 'complex_words_training.txt'\n",
    "performance = all_complex(data_file)\n",
    "print('Training precision: ' + str(performance[0]))\n",
    "print('Training recall: ' + str(performance[1]))\n",
    "print('Training f-score: ' + str(performance[2]))\n",
    "\n",
    "data_file = 'complex_words_development.txt'\n",
    "performance = all_complex(data_file)\n",
    "print('Development precision: ' + str(performance[0]))\n",
    "print('Development recall: ' + str(performance[1]))\n",
    "print('Development f-score: ' + str(performance[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code computed the precision, recall and f-score for the training and develpoment datasets, when the predictions are all complex. The precision for both datasets is about 40%. Since we predicted all comlpex, this number is actually the number of coplex words in the dataset. The recall is naturally 1.0, since there are no \"negative\" predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Word Length Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n for training set: 6\n",
      "Best n for development set: 6\n",
      "[0.6007401315789473, 0.8440207972270364, 0.7018976699495555]\n",
      "[0.6053511705685619, 0.8660287081339713, 0.7125984251968505]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "### 1.2.2: Word length thresholding\n",
    "\n",
    "## Finds the best length threshold by f-score, and uses this threshold to\n",
    "## classify the training and development set\n",
    "def word_length_threshold(training_file, development_file):\n",
    "    # compute predictions for training set\n",
    "    words_train, y_true_train = load_file(training_file)\n",
    "    max_length = len(max(words_train, key=len)) # the maximal length of a word\n",
    "    tfscore = 0\n",
    "    best_n = 0\n",
    "    tprecision_list = list()\n",
    "    trecall_list = list()\n",
    "    for n in range(2, max_length):\n",
    "        y_pred_train = list()\n",
    "        for i in range(len(words_train)):\n",
    "            y_pred_train.append(len(words_train[i]) > n)\n",
    "        tprecision_list.append(get_precision(y_pred_train, y_true_train))\n",
    "        trecall_list.append(get_recall(y_pred_train, y_true_train))\n",
    "        temp_fscore = get_fscore(y_pred_train, y_true_train)\n",
    "        if temp_fscore > tfscore:\n",
    "            tfscore = temp_fscore\n",
    "            best_n = n\n",
    "    print('Best n for training set: ' + str(best_n))\n",
    "    \n",
    "    # plot training set recall-precision curve\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(trecall_list, tprecision_list, label='training set', linewidth=2)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "        \n",
    "\n",
    "    # compute precision, recall and fscore for best n\n",
    "    y_pred_train = list()\n",
    "    for i in range(len(words_train)):\n",
    "        y_pred_train.append(len(words_train[i]) > best_n)\n",
    "    tprecision = get_precision(y_pred_train, y_true_train)\n",
    "    trecall = get_recall(y_pred_train, y_true_train)\n",
    "\n",
    "    # compute predictions for dev set\n",
    "    words_dev, y_true_dev = load_file(development_file)\n",
    "    max_length = len(max(words_dev, key=len))  # the maximal length of a word\n",
    "    dfscore = 0\n",
    "    best_n = 0\n",
    "    dprecision_list = list()\n",
    "    drecall_list = list()\n",
    "    for n in range(2, max_length):\n",
    "        y_pred_dev = list()\n",
    "        for i in range(len(words_dev)):\n",
    "            y_pred_dev.append(len(words_dev[i]) > n)\n",
    "        dprecision_list.append(get_precision(y_pred_dev, y_true_dev))\n",
    "        drecall_list.append(get_recall(y_pred_dev, y_true_dev))\n",
    "        temp_fscore = get_fscore(y_pred_dev, y_true_dev)\n",
    "        if temp_fscore > dfscore:\n",
    "            dfscore = temp_fscore\n",
    "            best_n = n\n",
    "    print('Best n for development set: ' + str(best_n))\n",
    "    \n",
    "    # plot training set recall-precision curve\n",
    "    ax.plot(drecall_list, dprecision_list, label='development set')\n",
    "    ax.legend(loc='upper right', fontsize='x-large')    \n",
    "\n",
    "    # compute precision, recall and fscore for best n\n",
    "    y_pred_dev = list()\n",
    "    for i in range(len(words_dev)):\n",
    "        y_pred_dev.append(len(words_dev[i]) > best_n)\n",
    "    dprecision = get_precision(y_pred_dev, y_true_dev)\n",
    "    drecall = get_recall(y_pred_dev, y_true_dev)\n",
    "\n",
    "    training_performance = [tprecision, trecall, tfscore]\n",
    "    development_performance = [dprecision, drecall, dfscore]\n",
    "    return training_performance, development_performance\n",
    "\n",
    "training_performance, development_performance = word_length_threshold('complex_words_training.txt', 'complex_words_development.txt')\n",
    "print(training_performance)\n",
    "print(development_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function tests different word lengths as calissification parameter, and chooses the length (n) which yields the highest f-score. We tested with word length between 2 and the length of the longest word in the dataset minus 1. Testing the length of the longest word as a threshold is equivalent to making only negative predictions, which leads to a problem in computing the precision and the recall (division in zero). The best f-score for both training and development sets was recived for n=6. The precision is about 0.6, and the recall 0.85.\n",
    "<br><br>\n",
    "We also plotted the precision-recall curve of the training and delopment datasets for the various word length. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Word Frequency Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4167701       7       1       1       2       0       1       0       0\n",
      "       1]\n",
      "[4.00000000e+01 4.73768300e+09 9.47536596e+09 1.42130489e+10\n",
      " 1.89507319e+10 2.36884148e+10 2.84260978e+10 3.31637808e+10\n",
      " 3.79014637e+10 4.26391467e+10 4.73768297e+10]\n",
      "4737683001.1\n",
      "Best threshold for training set: 50000000\n",
      "Best threshold for development set: 14900000\n",
      "Training set performance: [0.5657051282051282, 0.8157134604274986, 0.6680861130825645]\n",
      "Development set performance: [0.5824742268041238, 0.8110047846889952, 0.6779999999999999]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import gzip\n",
    "import numpy as np\n",
    "### 1.2.3: Word frequency thresholding\n",
    "\n",
    "## Loads Google NGram counts\n",
    "def load_ngram_counts(ngram_counts_file):\n",
    "    counts = defaultdict(int)\n",
    "    with gzip.open(ngram_counts_file, 'rt', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            token, count = line.strip().split('\\t')\n",
    "            if token[0].islower():\n",
    "                counts[token] = int(count)\n",
    "    return counts\n",
    "\n",
    "# Finds the best frequency threshold by f-score, and uses this threshold to\n",
    "## classify the training and development set\n",
    "def word_frequency_threshold(training_file, development_file, counts):\n",
    "    \n",
    "    thresholds = range(1000000, 50100000, 100000)\n",
    "    # compute predictions for training set\n",
    "    words_train, y_true_train = load_file(training_file)\n",
    "    tfscore = 0\n",
    "    best_threshold = 0\n",
    "    tprecision_list = list()\n",
    "    trecall_list = list()\n",
    "    for threshold in thresholds:\n",
    "        y_pred_train = list()\n",
    "        for word in words_train:\n",
    "            f = 0\n",
    "            if word in counts:\n",
    "                f = counts[word]\n",
    "            y_pred_train.append(f < threshold)\n",
    "        tprecision_list.append(get_precision(y_pred_train, y_true_train))\n",
    "        trecall_list.append(get_recall(y_pred_train, y_true_train))\n",
    "        temp_fscore = get_fscore(y_pred_train, y_true_train)\n",
    "        if temp_fscore > tfscore:\n",
    "            tfscore = temp_fscore\n",
    "            best_threshold = threshold\n",
    "    print('Best threshold for training set: ' + str(threshold))\n",
    "    \n",
    "    # get precision and recall for best threshold\n",
    "    tprecision = tprecision_list[thresholds.index(best_threshold)]\n",
    "    trecall = trecall_list[thresholds.index(best_threshold)]\n",
    "    \n",
    "    # plot training set recall-precision curve\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(trecall_list, tprecision_list, label='training set', linewidth=2)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    \n",
    "          \n",
    "    # compute predictions for dev set\n",
    "    words_dev, y_true_dev = load_file(development_file)\n",
    "    dfscore = 0\n",
    "    best_threshold = 0\n",
    "    dprecision_list = list()\n",
    "    drecall_list = list()\n",
    "    for threshold in thresholds:\n",
    "        y_pred_dev = list()\n",
    "        for word in words_dev:\n",
    "            f = 0\n",
    "            if word in counts:\n",
    "                f = counts[word]\n",
    "            y_pred_dev.append(f < threshold)\n",
    "        dprecision_list.append(get_precision(y_pred_dev, y_true_dev))\n",
    "        drecall_list.append(get_recall(y_pred_dev, y_true_dev))\n",
    "        temp_fscore = get_fscore(y_pred_dev, y_true_dev)\n",
    "        if temp_fscore > dfscore:\n",
    "            dfscore = temp_fscore\n",
    "            best_threshold = threshold\n",
    "    print('Best threshold for development set: ' + str(best_threshold))\n",
    "    \n",
    "    # compute precision, recall and fscore for best n\n",
    "    dprecision = dprecision_list[thresholds.index(best_threshold)]\n",
    "    drecall = drecall_list[thresholds.index(best_threshold)]\n",
    "    \n",
    "    # plot precision-recall curve for development set\n",
    "    ax.plot(drecall_list, dprecision_list, label='development set')\n",
    "    ax.legend(loc='lower center', fontsize='x-large')\n",
    "\n",
    "    training_performance = [tprecision, trecall, tfscore]\n",
    "    development_performance = [dprecision, drecall, dfscore]\n",
    "    return training_performance, development_performance\n",
    "\n",
    "# print histogram of counts\n",
    "counts = load_ngram_counts('ngram_counts.txt.gz')  # load word frequencies\n",
    "data = list(counts.values())\n",
    "hist, bin_edges = np.histogram(data, bins=10)\n",
    "print(hist)\n",
    "print(bin_edges)\n",
    "print(bin_edges[1])\n",
    "\n",
    "\n",
    "training_performance, development_performance = word_frequency_threshold('complex_words_training.txt', 'complex_words_development.txt', counts)\n",
    "print('Training set performance: ' + str(training_performance))\n",
    "print('Development set performance: ' + str(development_performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code computes the precision, recall and f-score of the training and development datasets, when the predictions are made using a threshold of frequencies. First, we look at the histogram and the bin edges of Google's word frequencies file. It is possible to see that the vast majority of the words are in the first bin of the histogram, which its upper edge it about 50 million. And so we use a threshold with skips of 100,000 up to 50 million. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3 Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance: [0.4950379451255108, 0.9797804737146159, 0.6577467519875897]\n",
      "Development set performance: [0.46929316338354576, 0.9688995215311005, 0.6323185011709602]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def naive_bayes(training_file, development_file, counts):\n",
    "    \n",
    "    # build X_train\n",
    "    words_train, y_true_train = load_file(training_file)\n",
    "    X_train = list()\n",
    "    for word in words_train:\n",
    "        l = len(word)\n",
    "        f = 0\n",
    "        if word in counts:\n",
    "            f = counts[word]\n",
    "        X_train.append([l, f])\n",
    "    \n",
    "    # normalize X_train\n",
    "    X_train_matrix = np.matrix(X_train)\n",
    "    X_train_mean = X_train_matrix.mean(0)\n",
    "    X_train_std = X_train_matrix.std(0)\n",
    "    X_train_matrix = (X_train_matrix - X_train_mean) / X_train_std\n",
    "    \n",
    "    # learn classifier\n",
    "    Y = np.array(y_true_train)\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train_matrix, Y)\n",
    "    \n",
    "    # use classify to predict training set labels\n",
    "    Y_pred_train = clf.predict(X_train_matrix)\n",
    "    # compute precision, recall and f-score for the training predicted lables\n",
    "    tprecision = get_precision(Y_pred_train.tolist(), y_true_train)\n",
    "    trecall = get_recall(Y_pred_train.tolist(), y_true_train)\n",
    "    tfscore = get_fscore(Y_pred_train.tolist(), y_true_train)\n",
    "    training_performance = [tprecision, trecall, tfscore]\n",
    "    \n",
    "    # build X_dev\n",
    "    words_dev, y_true_dev = load_file(development_file)\n",
    "    X_dev = list()\n",
    "    for word in words_dev:\n",
    "        l = len(word)\n",
    "        f = 0\n",
    "        if word in counts:\n",
    "            f = counts[word]\n",
    "        X_dev.append([l, f])\n",
    "        \n",
    "    # normalize X_dev\n",
    "    X_dev_matrix = np.matrix(X_dev)\n",
    "    X_dev_matrix = (X_dev_matrix - X_train_mean) / X_train_std\n",
    "    \n",
    "    # use classifier to predict development set labels\n",
    "    Y_pred_dev = clf.predict(X_dev_matrix)\n",
    "    # compute precision, recall and f-score for the training predicted lables\n",
    "    dprecision = get_precision(Y_pred_dev.tolist(), y_true_dev)\n",
    "    drecall = get_recall(Y_pred_dev.tolist(), y_true_dev)\n",
    "    dfscore = get_fscore(Y_pred_dev.tolist(), y_true_dev)\n",
    "    development_performance = [dprecision, drecall, dfscore]\n",
    "    \n",
    "    return training_performance, development_performance\n",
    "        \n",
    "counts = load_ngram_counts('ngram_counts.txt.gz')  # load word frequencies\n",
    "training_performance, development_performance = naive_bayes('complex_words_training.txt', 'complex_words_development.txt', counts)\n",
    "print('Training set performance: ' + str(training_performance))\n",
    "print('Development set performance: ' + str(development_performance))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code learns a Naive Bayes classifier with the training set, and then computes the precision, recall and f-score of the labels predicted by the model for the training set and development set. The precision and recall of both training and developemnt sets are quite simillar to the performance of the majority class baseline. This means that the classifier has a strong bias towards the positive labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.4. Ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['campaign', 'commissioner', 'district', 'element', 'hoverboard', 'indy', 'inspired', 'league', 'opponents', 'slavery', 'sprouts']\n"
     ]
    }
   ],
   "source": [
    "#  print context-sensitive words\n",
    "words, y_true = load_file('complex_words_training.txt')\n",
    "words_array = np.array(words)\n",
    "context_sensitive = list()\n",
    "for word in words:\n",
    "    searchval = word\n",
    "    inds = np.where(words_array == searchval)[0]\n",
    "    labels = [y_true[i] for i in inds.tolist()] # get all labels of the word\n",
    "    max_label = max(labels)\n",
    "    if sum(labels) != max_label*len(labels): # check if the word has different labels\n",
    "        context_sensitive.append(word)\n",
    "\n",
    "print(sorted(set(context_sensitive)))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code prints all words in complex_words_training.txt that are labeled both complex and simple, meaning that their label is context-sensitive. Out of 3882 different words, 11 are context-sensitive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2  Document Classification\n",
    "## Q2.1. Reuters Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Eustache Diemert <eustache@diemert.fr>\n",
    "#          @FedericoV <https://github.com/FedericoV/>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "from glob import glob\n",
    "import itertools\n",
    "import os.path\n",
    "import re\n",
    "import tarfile\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from sklearn.externals.six.moves import html_parser\n",
    "from sklearn.externals.six.moves.urllib.request import urlretrieve\n",
    "from sklearn.datasets import get_data_home\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "def _not_in_sphinx():\n",
    "    # Hack to detect whether we are running by the sphinx builder\n",
    "    return '__file__' in globals()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReutersParser(html_parser.HTMLParser):\n",
    "    \"\"\"Utility class to parse a SGML file and yield documents one at a time.\"\"\"\n",
    "\n",
    "    def __init__(self, encoding='latin-1'):\n",
    "        html_parser.HTMLParser.__init__(self)\n",
    "        self._reset()\n",
    "        self.encoding = encoding\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        method = 'start_' + tag\n",
    "        getattr(self, method, lambda x: None)(attrs)\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        method = 'end_' + tag\n",
    "        getattr(self, method, lambda: None)()\n",
    "\n",
    "    def _reset(self):\n",
    "        self.in_title = 0\n",
    "        self.in_body = 0\n",
    "        self.in_topics = 0\n",
    "        self.in_topic_d = 0\n",
    "        self.title = \"\"\n",
    "        self.body = \"\"\n",
    "        self.topics = []\n",
    "        self.topic_d = \"\"\n",
    "\n",
    "    def parse(self, fd):\n",
    "        self.docs = []\n",
    "        for chunk in fd:\n",
    "            self.feed(chunk.decode(self.encoding))\n",
    "            for doc in self.docs:\n",
    "                yield doc\n",
    "            self.docs = []\n",
    "        self.close()\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        if self.in_body:\n",
    "            self.body += data\n",
    "        elif self.in_title:\n",
    "            self.title += data\n",
    "        elif self.in_topic_d:\n",
    "            self.topic_d += data\n",
    "\n",
    "    def start_reuters(self, attributes):\n",
    "        pass\n",
    "\n",
    "    def end_reuters(self):\n",
    "        self.body = re.sub(r'\\s+', r' ', self.body)\n",
    "        self.docs.append({'title': self.title,\n",
    "                          'body': self.body,\n",
    "                          'topics': self.topics})\n",
    "        self._reset()\n",
    "\n",
    "    def start_title(self, attributes):\n",
    "        self.in_title = 1\n",
    "\n",
    "    def end_title(self):\n",
    "        self.in_title = 0\n",
    "\n",
    "    def start_body(self, attributes):\n",
    "        self.in_body = 1\n",
    "\n",
    "    def end_body(self):\n",
    "        self.in_body = 0\n",
    "\n",
    "    def start_topics(self, attributes):\n",
    "        self.in_topics = 1\n",
    "\n",
    "    def end_topics(self):\n",
    "        self.in_topics = 0\n",
    "\n",
    "    def start_d(self, attributes):\n",
    "        self.in_topic_d = 1\n",
    "\n",
    "    def end_d(self):\n",
    "        self.in_topic_d = 0\n",
    "        self.topics.append(self.topic_d)\n",
    "        self.topic_d = \"\"\n",
    "\n",
    "\n",
    "def stream_reuters_documents(data_path=None):\n",
    "    \"\"\"Iterate over documents of the Reuters dataset.\n",
    "\n",
    "    The Reuters archive will automatically be downloaded and uncompressed if\n",
    "    the `data_path` directory does not exist.\n",
    "\n",
    "    Documents are represented as dictionaries with 'body' (str),\n",
    "    'title' (str), 'topics' (list(str)) keys.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    DOWNLOAD_URL = ('http://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "                    'reuters21578-mld/reuters21578.tar.gz')\n",
    "    ARCHIVE_FILENAME = 'reuters21578.tar.gz'\n",
    "\n",
    "    if data_path is None:\n",
    "        data_path = os.path.join(get_data_home(), \"reuters\")\n",
    "    if not os.path.exists(data_path):\n",
    "        \"\"\"Download the dataset.\"\"\"\n",
    "        print(\"downloading dataset (once and for all) into %s\" %\n",
    "              data_path)\n",
    "        os.mkdir(data_path)\n",
    "\n",
    "        def progress(blocknum, bs, size):\n",
    "            total_sz_mb = '%.2f MB' % (size / 1e6)\n",
    "            current_sz_mb = '%.2f MB' % ((blocknum * bs) / 1e6)\n",
    "            if _not_in_sphinx():\n",
    "                sys.stdout.write(\n",
    "                    '\\rdownloaded %s / %s' % (current_sz_mb, total_sz_mb))\n",
    "\n",
    "        archive_path = os.path.join(data_path, ARCHIVE_FILENAME)\n",
    "        urlretrieve(DOWNLOAD_URL, filename=archive_path,\n",
    "                    reporthook=progress)\n",
    "        if _not_in_sphinx():\n",
    "            sys.stdout.write('\\r')\n",
    "        print(\"untarring Reuters dataset...\")\n",
    "        tarfile.open(archive_path, 'r:gz').extractall(data_path)\n",
    "        print(\"done.\")\n",
    "\n",
    "    parser = ReutersParser()\n",
    "    for filename in glob(os.path.join(data_path, \"*.sgm\")):\n",
    "        for doc in parser.parse(open(filename, 'rb')):\n",
    "            yield doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 21578\n",
      "Number of categories: 445\n",
      "Mean: 89.87191011235954\n",
      "Std: 644.6569094125375\n",
      "Min: 1.0\n",
      "Max: 12542.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# get iterator of Reuters-21578\n",
    "data_stream = stream_reuters_documents()\n",
    "\n",
    "topics = defaultdict(int)\n",
    "num_docs = 0\n",
    "for doc in data_stream:\n",
    "    num_docs += 1\n",
    "    for topic in doc['topics']:\n",
    "        topics[topic] += 1\n",
    "        \n",
    "print('Number of documents: ' + str(num_docs))\n",
    "print('Number of categories: ' + str(len(topics)))\n",
    "\n",
    "statistics = pd.Series(stats).describe()\n",
    "print('Mean: ' + str(statistics['mean']))\n",
    "print('Std: ' + str(statistics['std']))\n",
    "print('Min: ' + str(statistics['min']))\n",
    "print('Max: ' + str(statistics['max']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 21,578 different documents in the dataset, and 445 different topics/categories. The average number of documents per topic is ~90, and the most popular category has 12,542 documents assigned to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 16003823\n",
      "Number of words: 2638722\n"
     ]
    }
   ],
   "source": [
    "positive_class = 'acq'\n",
    "def get_minibatch(doc_iter, size, pos_class=positive_class):\n",
    "    \"\"\"Extract a minibatch of examples, return a tuple X_text, y.\n",
    "\n",
    "    Note: size is before excluding invalid docs with no topics assigned.\n",
    "\n",
    "    \"\"\"\n",
    "    data = [(u'{title}\\n\\n{body}'.format(**doc), pos_class in doc['topics'])\n",
    "            for doc in itertools.islice(doc_iter, size)\n",
    "            if doc['topics']]\n",
    "    if not len(data):\n",
    "        return np.asarray([], dtype=int), np.asarray([], dtype=int)\n",
    "    X_text, y = zip(*data)\n",
    "    return X_text, np.asarray(y, dtype=int)\n",
    "\n",
    "data_stream = stream_reuters_documents()\n",
    "\n",
    "num_chars = 0\n",
    "num_words = 0\n",
    "examps = get_minibatch(data_stream, 21578) # get all documents\n",
    "for doc in examps[0]:\n",
    "    num_chars += len(doc)\n",
    "    num_words += len(doc.split())\n",
    "\n",
    "print('Number of characters: ' + str(num_chars))\n",
    "print('Number of words: ' + str(num_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code prints the number of characters and words in the corpus. We treat a word as a token with space before or after it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code discusses the following classifiers: stochastic gradient decent (SGD), perceptron, multinomial naive Bayes, and passive-agressive. All these classifiers allow to perform the training phase in batches, i.e. they don't have to see all the training data at once. This is why these classifiers support the 'partial-fit' method, which doesn't load all the data at once to the memory, but does so in batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashing vectorizer is a function of sklearn which is used for feature representation in online learning. Since the data is seen in batches, we cannot hold the entire vocabulary, and so the function allows to pick in advance the size of the feature space (with the argument n_features), and then all features in each batch wil be projected on this space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Spam Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent: [##################################################] 100%"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "def progress(i, end_val, bar_length=50):\n",
    "    '''\n",
    "    Print a progress bar of the form: Percent: [#####      ]\n",
    "    i is the current progress value expected in a range [0..end_val]\n",
    "    bar_length is the width of the progress bar on the screen.\n",
    "    '''\n",
    "    percent = float(i) / end_val\n",
    "    hashes = '#' * int(round(percent * bar_length))\n",
    "    spaces = ' ' * (bar_length - len(hashes))\n",
    "    sys.stdout.write(\"\\rPercent: [{0}] {1}%\".format(hashes + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "NEWLINE = '\\n'\n",
    "\n",
    "HAM = 'ham'\n",
    "SPAM = 'spam'\n",
    "\n",
    "SOURCES = [\n",
    "    ('spam',        SPAM),\n",
    "    ('easy_ham',    HAM),\n",
    "    ('hard_ham',    HAM),\n",
    "    ('beck-s',      HAM),\n",
    "    ('farmer-d',    HAM),\n",
    "    ('kaminski-v',  HAM),\n",
    "    ('kitchen-l',   HAM),\n",
    "    ('lokay-m',     HAM),\n",
    "    ('williams-w3', HAM),\n",
    "    ('BG',          SPAM),\n",
    "    ('GP',          SPAM),\n",
    "    ('SH',          SPAM)\n",
    "]\n",
    "\n",
    "SKIP_FILES = {'cmds'}\n",
    "\n",
    "\n",
    "def read_files(path):\n",
    "    '''\n",
    "    Generator of pairs (filename, filecontent)\n",
    "    for all files below path whose name is not in SKIP_FILES.\n",
    "    The content of the file is of the form:\n",
    "        header....\n",
    "        <emptyline>\n",
    "        body...\n",
    "    This skips the headers and returns body only.\n",
    "    '''\n",
    "    for root, dir_names, file_names in os.walk(path):\n",
    "        for path in dir_names:\n",
    "            read_files(os.path.join(root, path))\n",
    "        for file_name in file_names:\n",
    "            if file_name not in SKIP_FILES:\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    past_header, lines = False, []\n",
    "                    f = open(file_path, encoding=\"latin-1\")\n",
    "                    for line in f:\n",
    "                        if past_header:\n",
    "                            lines.append(line)\n",
    "                        elif line == NEWLINE:\n",
    "                            past_header = True\n",
    "                    f.close()\n",
    "                    content = NEWLINE.join(lines)\n",
    "                    yield file_path, content\n",
    "\n",
    "\n",
    "def build_data_frame(l, path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for i, (file_name, text) in enumerate(read_files(path)):\n",
    "        if ((i+l) % 100 == 0):\n",
    "            progress(i+l, 58910, 50)\n",
    "        rows.append({'text': text, 'class': classification})\n",
    "        index.append(file_name)\n",
    "   \n",
    "    data_frame = DataFrame(rows, index=index)\n",
    "    return data_frame, len(rows)\n",
    "\n",
    "def load_data():\n",
    "    data = DataFrame({'text': [], 'class': []})\n",
    "    l = 0\n",
    "    for path, classification in SOURCES:\n",
    "        data_frame, nrows = build_data_frame(l, path, classification)\n",
    "        data = data.append(data_frame, sort=False)\n",
    "        l += nrows\n",
    "    data = data.reindex(numpy.random.permutation(data.index))\n",
    "    return data\n",
    "\n",
    "data=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unigrams: 697570\n",
      "Number of bigrams: 3318380\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "counts_mat = count_vectorizer.fit_transform(data['text'].values)\n",
    "features = count_vectorizer.get_feature_names()\n",
    "num_bigrams = 0\n",
    "# if the feature contains space, it's a bigram\n",
    "for f in features:\n",
    "    if ' ' in f:\n",
    "        num_bigrams += 1\n",
    "num_unigrams = len(features) - num_bigrams\n",
    "print('Number of unigrams: ' + str(num_unigrams))\n",
    "print('Number of bigrams: ' + str(num_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 unigrams and bigrams: ['font', '3d', 'the', 'br', 'td', 'to', 'and', 'nbsp', 'of', 'http', '20', 'size', 'tr', 'in', 'width', 'com', 'nbsp nbsp', 'you', 'br br', 'face', 'for', 'border', 'is', 'style', 'this', 'align', 'span', 'href', 'height', 'html', 'color', 'www', 'font size', 'td tr', 'http www', 'font face', 'that', 'on', 'td td', 'your', 'content', 'tr td', 'table', 'with', 'be', 'div', '3d http', 'arial', 'it', 'style 3d']\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "def top_n_unigrams_bigrams(counts_mat, features_names, n = 50):\n",
    "    counts_vec = counts_mat.sum(axis=0) # get counts for each feature\n",
    "    counts_vec = np.squeeze(np.asarray(counts_vec))\n",
    "    most_freq_inds = heapq.nlargest(n, range(len(counts_vec)), counts_vec.__getitem__) # get n most frequent features\n",
    "    most_freq_features = [features_names[i] for i in most_freq_inds]\n",
    "    return most_freq_features\n",
    "\n",
    "# get top 50 for the entire dataset\n",
    "n=50\n",
    "most_freq_features = top_n_unigrams_bigrams(counts_mat, features)\n",
    "print('Top ' + str(n) + ' unigrams and bigrams: ' + str(most_freq_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 unigrams and bigrams in spam data: ['corporate functions', '2220 pdt', 'apocalyptical adipescent', 'major ity', 'growth was', 'markets calm', 'leaden yesterday', 'miltuykjynqhaajdboefgfzesuyvkhg br', 'meteorology bargaininternational', '15 transmission', 'doors comes', '_nextpart_095_8247_18l6xskw z92s6715', 'gtooofsweii pq0de5kszbpkavs', 'now recognised', 'his brown', 'appointed administrators', 'competentba nk', 'antoine jacoutot', 'loud disruption', 'likely decrease', '99zjxhqbfw8eb2dmxotmpeurargwhe2lg rgcg6dvegzzknw9twphco5y5sqdcms8lw', 'bhwcpybz', 'edna consonant', 'bgfzig9yz2fuaxphy2lvbmvzihzpdmvuigvuihvuigvudg9ybm8gzgvtyxnpywrvigrpbuftawnv lcbwb3igbg8gcxvligvzig5ly2vzyxjpbybjb250yxigy29uigluzm9ybwfjafnuig9wb3j0dw5h', 'dog grew', 'or knows', 'correl', 'doctor cost', 'diatonic iconoclast', 'make molded', 'corporativos span', 'bonneville replied', 'make manual', 'englishman halpern', 'mdt01vy', 'oef91irqioazata4b9i5xz4omftjzmncrfgizbjnee br', 'canteen terna', 'mimicking commonweal', 'corwinsaskia bach', '24 swift', 'loud funny', 'ora2ll5ru3ltq92uzp7nm', 'drinking homebrew', 'ackehlxssrydgimzgvbfj 79286922', 'mag 15', 'bank president', 'correlation disappears', 'maommkwb54', 'mimiery font', 'doctor distiller']\n"
     ]
    }
   ],
   "source": [
    "# get top 50 for spam data\n",
    "spam_data = data[data['class'] == 'spam']\n",
    "spam_cv = CountVectorizer(ngram_range=(1, 2))\n",
    "spam_counts_mat = spam_cv.fit_transform(spam_data['text'].values)\n",
    "most_freq_features = top_n_unigrams_bigrams(spam_counts_mat, features)\n",
    "print('Top ' + str(n) + ' unigrams and bigrams in spam data: ' + str(most_freq_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 unigrams and bigrams in ham data: ['danger pass', 'dell until', '2924631', 'briefing charts', 'article 544', '666666 atenci', 'akemzs6irvdubnetivevy0v8hqt5safl', 'ac4tcxueeajgqssxu45wtkdvusdjjjm44 c9ufqkk', 'aufhaengevorrichtung', 'buiofe br', 'arachnophagous unintermittent', 'dach', 'eater spain', 'cwrl6zd5x byaaaa44xk02k', 'decdelmur iol', 'avec des', 'dunkirk so', '3d623 bgcolor', 'a_jimenezcrespo', '080e1813110307171e1b1c17001b1d1e1d3214131f1b1e0b5c061a171600131f131a1d0701175c111d1f0e43424b4b460e43410e400e404647434742430e08', 'dsm group', 'anne denne', 'alluum cl', 'dteriutcdvibagwslklubfbbaclhspa0ptvtrikrshxmswizvvibrstoz36isfiz7wlxm1u9 pry', 'e5yp7jh aasb0z9tzrrxva5kj', '374 3116', 'dovzh8ell8o1ctwjrm1 h7fzmlfehtftgn', '3d ak', 'architect braniff', '119 by', '3399 by', '4859009046597536 content', 'ajxuyzgmzzladxjkctglp6vmhxqsiltpwe8su7jcebam05lhrm7eufbw2brsxd6s6bxm1jcncxqk', 'bryanhoch gif', 'buyer such', 'details up', 'arget 3dhe', 'br specification', 'ebitda http', 'as playstation', '3y3dqxnm4bqajjoo3nt tkchbwsr', 'antivirus guide', '01 dolar', 'cotangent auschwitz', 'an analy', 'around picture', '279 o0', '02 2003', 'appropriable bluegrass', 'anglopho biaazw7vfc2roshpta']\n"
     ]
    }
   ],
   "source": [
    "# get top 50 for ham data\n",
    "ham_data = data[data['class'] == 'ham']\n",
    "ham_cv = CountVectorizer(ngram_range=(1, 2))\n",
    "ham_counts_mat = ham_cv.fit_transform(ham_data['text'].values)\n",
    "most_freq_features = top_n_unigrams_bigrams(ham_counts_mat, features)\n",
    "print('Top ' + str(n) + ' unigrams and bigrams in ham data: ' + str(most_freq_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above blocks prints the 50 most frequent unigrams and bigrams in the whole data, the spam data, and the ham data. The most frequent features in the entire dataset are mostly html code, which makes sense. We expect the content of spam and ham emails would be very different, and the commong attributes would be related to the fact that coth classes are email messages. The most frequent features in the spam data are mostly gibberish, which make sense. In the ham data we see also some gibberish, but also more meaningful expressions, such as: 'buyer such', 'avec des' (french), 'around picture', etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a naive Bayes classifier to classify spam and ham messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train naive Bayes classifier with unigrams and ngrams as features\n",
    "nb = MultinomialNB()\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "counts = cv.fit_transform(data['text'].values)\n",
    "nb.fit(counts, data['class'].values) \n",
    "\n",
    "# get 20 top features\n",
    "probs = nb.feature_log_prob_ # get log conditional probabibilities\n",
    "k = 20\n",
    "features_names1 = cv.get_feature_names()\n",
    "features_names2 = cv.get_feature_names()\n",
    "class1_probs = probs[0] # log probabilities of the first class\n",
    "sorted_probs1 = sorted(zip(class1_probs, features_names1))\n",
    "top1 = sorted_probs1[:-(k + 1):-1] # 20 most important features and their probabilities of the first class\n",
    "class2_probs = probs[1] # log probabilities of the second class\n",
    "sorted_probs2 = sorted(zip(class2_probs, features_names2))\n",
    "top2 = sorted_probs2[:-(k + 1):-1] # 20 most important features and their probabilities of the first class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tham:\t\t\tspam:\t\n",
      "\t-4.2286\tthe\t\t-4.2632\tfont\n",
      "\t-4.6092\tto\t\t-4.2940\t3d\n",
      "\t-5.0172\tand\t\t-4.4076\tbr\n",
      "\t-5.0764\tof\t\t-4.6910\ttd\n",
      "\t-5.3307\tin\t\t-4.9620\tnbsp\n",
      "\t-5.5690\tcom\t\t-5.0642\tthe\n",
      "\t-5.5769\tfor\t\t-5.2305\tsize\n",
      "\t-5.5848\tenron\t\t-5.2819\ttr\n",
      "\t-5.7376\tis\t\t-5.2999\tto\n",
      "\t-5.7526\ton\t\t-5.3275\t20\n",
      "\t-5.7700\thttp\t\t-5.3884\thttp\n",
      "\t-5.8141\tthat\t\t-5.3924\tand\n",
      "\t-5.9024\tyou\t\t-5.5075\tnbsp nbsp\n",
      "\t-5.9972\ttd\t\t-5.5114\twidth\n",
      "\t-6.0622\tthis\t\t-5.5179\tof\n",
      "\t-6.1127\tit\t\t-5.5466\tbr br\n",
      "\t-6.1510\twith\t\t-5.6205\tface\n",
      "\t-6.1732\tbe\t\t-5.7000\tborder\n",
      "\t-6.1842\tect\t\t-5.7171\tstyle\n",
      "\t-6.2129\t20\t\t-5.7663\tspan\n"
     ]
    }
   ],
   "source": [
    "# print\n",
    "top = zip(top1,top2)\n",
    "print(\"\\t%s\\t%s\\t\\t%s\\t%s\" %('ham:','','spam:',''))\n",
    "for (prob1, feature1), (prob2, feature2) in top:\n",
    "        print (\"\\t%.4f\\t%s\\t\\t%.4f\\t%s\" % (prob1, feature1, prob2, feature2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the NB model, we show the top 20 features per class with the highest log-probability. For example, given that the message is 'ham', the most probable feature is the word 'the'. The most probable features given that the message is 'ham' are connectors such as 'to', 'of', 'for', etc.. On the other hand, the most probable features given that the message is 'spam' are html words, such as 'font', 'br', 'nbsp', etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding the message length as a feature, it must be normalized. The reason is that the model perform better in the training stage when all features have the same mean and variance. In the case of the email message representation, counts of words would be small numbers, while the length could be significantly larger. We would expect Logistic regression to perform better, if adding the length of the message as a feature, since the naive Bayes assumption does not hold anymore. There is a strong dependency between the length of the message, and the unigrams and bigrams appear in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "# first we define a length transfomer\n",
    "class LengthTransformer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return DataFrame(len(item) for item in X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define length transformer, so we would be able to use FeatureUnion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('ngram', Pipeline([\n",
    "      ('counts', CountVectorizer(ngram_range=(1, 2))),\n",
    "     ])),\n",
    "    ('length', LengthTransformer())\n",
    "   ])),\n",
    "  ('classifier', MultinomialNB())\n",
    "])\n",
    "    return pipeline\n",
    "\n",
    "def train(data = None, n_folds = 6):\n",
    "    if data is None:\n",
    "        print(\"Loading data...\")\n",
    "        data = load_data()\n",
    "        print(\"Data loaded\")\n",
    "    k_fold = KFold(n_splits = n_folds)\n",
    "    pipeline = build_pipeline()\n",
    "    scores = []\n",
    "    confusion = numpy.array([[0, 0], [0, 0]])\n",
    "    print(\"Training with %d folds\" % n_folds)\n",
    "    for i, (train_indices, test_indices) in enumerate(k_fold.split(data)):\n",
    "        train_text = data.iloc[train_indices]['text'].values\n",
    "        train_y = data.iloc[train_indices]['class'].values.astype(str)\n",
    "\n",
    "        test_text = data.iloc[test_indices]['text'].values\n",
    "        test_y = data.iloc[test_indices]['class'].values.astype(str)\n",
    "\n",
    "        print(\"Training for fold %d\" % i)\n",
    "        pipeline.fit(train_text, train_y)\n",
    "        print(\"Testing for fold %d\" % i)\n",
    "        predictions = pipeline.predict(test_text)\n",
    "\n",
    "        confusion += confusion_matrix(test_y, predictions)\n",
    "        score = f1_score(test_y, predictions, pos_label=SPAM)\n",
    "        scores.append(score)\n",
    "        print(\"Score for %d: %2.2f\" % (i, score))\n",
    "        print(\"Confusion matrix for %d: \" % i)\n",
    "        print(confusion)\n",
    "\n",
    "    print('Total emails classified:', len(data))\n",
    "    print('Score:', sum(scores)/len(scores))\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a naive Bayes model with the new length feature, and test it in kfold approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 6 folds\n",
      "Training for fold 0\n",
      "Testing for fold 0\n",
      "Score for 0: 0.98\n",
      "Confusion matrix for 0: \n",
      "[[3814   26]\n",
      " [ 214 5765]]\n",
      "Training for fold 1\n",
      "Testing for fold 1\n",
      "Score for 1: 0.98\n",
      "Confusion matrix for 1: \n",
      "[[ 7698    44]\n",
      " [  433 11463]]\n",
      "Training for fold 2\n",
      "Testing for fold 2\n",
      "Score for 2: 0.98\n",
      "Confusion matrix for 2: \n",
      "[[11612    64]\n",
      " [  631 17149]]\n",
      "Training for fold 3\n",
      "Testing for fold 3\n",
      "Score for 3: 0.98\n",
      "Confusion matrix for 3: \n",
      "[[15546    82]\n",
      " [  825 22821]]\n",
      "Training for fold 4\n",
      "Testing for fold 4\n",
      "Score for 4: 0.98\n",
      "Confusion matrix for 4: \n",
      "[[19491   100]\n",
      " [ 1055 28446]]\n",
      "Training for fold 5\n",
      "Testing for fold 5\n",
      "Score for 5: 0.98\n",
      "Confusion matrix for 5: \n",
      "[[23427   112]\n",
      " [ 1222 34149]]\n",
      "Total emails classified: 58910\n",
      "Score: 0.9808435583149474\n",
      "Confusion matrix:\n",
      "[[23427   112]\n",
      " [ 1222 34149]]\n"
     ]
    }
   ],
   "source": [
    "pipeline_nb = train(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score for the naive Bayes classifier with the length as feature is 0.9808. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline2():\n",
    "    pipeline = Pipeline([\n",
    "        ('count_vectorizer',   CountVectorizer(ngram_range=(1, 2))),\n",
    "        ('classifier',         MultinomialNB())\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "def train2(data = None, n_folds = 4):\n",
    "    if data is None:\n",
    "        print(\"Loading data...\")\n",
    "        data = load_data()\n",
    "        print(\"Data loaded\")\n",
    "    k_fold = KFold(n_splits = n_folds)\n",
    "    pipeline = build_pipeline2()\n",
    "    scores = []\n",
    "    confusion = numpy.array([[0, 0], [0, 0]])\n",
    "    print(\"Training with %d folds\" % n_folds)\n",
    "    for i, (train_indices, test_indices) in enumerate(k_fold.split(data)):\n",
    "        train_text = data.iloc[train_indices]['text'].values\n",
    "        train_y = data.iloc[train_indices]['class'].values.astype(str)\n",
    "        test_text = data.iloc[test_indices]['text'].values\n",
    "        test_y = data.iloc[test_indices]['class'].values.astype(str)\n",
    "        \n",
    "        print(\"Training for fold %d\" % i)\n",
    "        pipeline.fit(train_text, train_y)\n",
    "        print(\"Testing for fold %d\" % i)\n",
    "        predictions = pipeline.predict(test_text)\n",
    "        \n",
    "        confusion += confusion_matrix(test_y, predictions)\n",
    "        score = f1_score(test_y, predictions, pos_label=SPAM)\n",
    "        scores.append(score)\n",
    "        \n",
    "        print(\"Score for %d: %2.2f\" % (i, score))\n",
    "        print(\"Confusion matrix for %d: \" % i)\n",
    "        print(confusion)\n",
    "\n",
    "    print('Total emails classified:', len(data))\n",
    "    print('Score:', sum(scores)/len(scores))\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion)\n",
    "    return pipeline\n",
    "    confusion = confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=SPAM)\n",
    "    print(\"Score for %d: %2.2f\" % (i, score))\n",
    "    print(\"Confusion matrix for %d: \" % i)\n",
    "    print(confusion)\n",
    "    print('Total emails classified:', len(test_text))\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we test the model without the length feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 4 folds\n",
      "Training for fold 0\n",
      "Testing for fold 0\n",
      "Score for 0: 0.98\n",
      "Confusion matrix for 0: \n",
      "[[5734   27]\n",
      " [ 388 8579]]\n",
      "Training for fold 1\n",
      "Testing for fold 1\n",
      "Score for 1: 0.98\n",
      "Confusion matrix for 1: \n",
      "[[11633    43]\n",
      " [  757 17023]]\n",
      "Training for fold 2\n",
      "Testing for fold 2\n",
      "Score for 2: 0.98\n",
      "Confusion matrix for 2: \n",
      "[[17549    64]\n",
      " [ 1124 25446]]\n",
      "Training for fold 3\n",
      "Testing for fold 3\n",
      "Score for 3: 0.98\n",
      "Confusion matrix for 3: \n",
      "[[23456    83]\n",
      " [ 1464 33907]]\n",
      "Total emails classified: 58910\n",
      "Score: 0.9777018018663246\n",
      "Confusion matrix:\n",
      "[[23456    83]\n",
      " [ 1464 33907]]\n"
     ]
    }
   ],
   "source": [
    "nb2_pipeline = train2(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score withouth the length feature is 0.9561, meaning the length feature did improve the prediction of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
